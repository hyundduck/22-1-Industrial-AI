{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_dataset(Dataset):\n",
    "    def __init__(self, imgs, labels, transform = None):\n",
    "        super(train_dataset, self).__init__()\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        assert len(self.imgs) == len(self.labels)\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = np.array(Image.open(self.imgs[idx]))\n",
    "        y = label_map[self.labels[idx]]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image = X)['image']\n",
    "        else:\n",
    "            img = X\n",
    "    \n",
    "        y = torch.tensor(y, dtype = torch.long)\n",
    "        return {\n",
    "            'img' : img,\n",
    "            'label' : y\n",
    "        }\n",
    "    \n",
    "class test_dataset(Dataset):\n",
    "    def __init__(self, imgs, transform = None):\n",
    "        super(test_dataset, self).__init__()\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        # self.n_tta = n_tta\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = np.array(Image.open(self.imgs[idx]))\n",
    "        if self.transform:\n",
    "            img = self.transform(image = X)['image']\n",
    "            return img\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(128, 128, interpolation=cv2.INTER_AREA),\n",
    "    A.HorizontalFlip(),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit = 3, p = 0.2),\n",
    "        A.MedianBlur(blur_limit = 3, p = 0.1),\n",
    "        A.Blur(blur_limit = 3, p = 0.1),\n",
    "        ], p = 0.2),\n",
    "    A.ShiftScaleRotate(rotate_limit = 30),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(p = 1.0),\n",
    "        A.GridDistortion(p = 1.0),\n",
    "        ], p = 0.3),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit = 2),\n",
    "        A.RandomBrightnessContrast(),\n",
    "        ], p = 0.3),\n",
    "    A.HueSaturationValue(p = 0.3),\n",
    "    A.Normalize(mean=(R_mean, G_mean, B_mean), std=(R_std, G_std, B_std)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "else_transform = A.Compose([\n",
    "    A.Resize(128, 128, interpolation=cv2.INTER_AREA),\n",
    "    A.Normalize(mean=(R_mean, G_mean, B_mean), std=(R_std, G_std, B_std)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_batch_size = 64\n",
    "valid_batch_size = 128\n",
    "test_batch_size = 127\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "save_name = f'js_effb0_b{train_batch_size}_e{epochs}_lr{learning_rate}'\n",
    "save_path = f'models/{save_name}.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "\n",
    "def train(model, loader, epoch, nb_epochs):\n",
    "    print(f'Epoch {epoch+1}/{nb_epochs}')\n",
    "    running_loss = 0.0\n",
    "    running_f1 = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train()\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for idx, batch in enumerate(tqdm(loader)):\n",
    "        img = batch['img'].float().to(device)\n",
    "        label = batch['label'].long().to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        #     output = model(img, csv_feature)\n",
    "        #     loss = criterion(output, label)\n",
    "\n",
    "        # scaler.scale(loss).backward() # ADDED - mixed precision + gradient clipping\n",
    "        # nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        # scaler.step(optimizer)\n",
    "        # scaler.update()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        output = model(img)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # stats\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        correct = torch.eq(preds, label).sum()\n",
    "        running_loss += loss.item() \n",
    "        running_corrects+=correct\n",
    "        \n",
    "        for item in label.cpu().numpy():\n",
    "            y_true.append(item)\n",
    "        for item in preds.cpu().numpy():\n",
    "            y_pred.append(item)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = running_corrects / len(loader.dataset)\n",
    "    epoch_f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    epoch_f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    writer.add_scalar('Loss/Train', epoch_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Train', epoch_acc, epoch)\n",
    "    writer.add_scalar('F1_macro/Train', epoch_f1_macro, epoch)\n",
    "    writer.add_scalar('F1_weighted/Train', epoch_f1_weighted, epoch)\n",
    "    writer.add_scalar('learning_rate', optimizer.param_groups[0][\"lr\"], epoch)\n",
    "\n",
    "    print(f'Train loss: {epoch_loss:.6f}, Train ACC: {epoch_acc:.6f}, F1_macro: {epoch_f1_macro:.6f}, F1_weighted: {epoch_f1_weighted:.6f} lr: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    # scheduler.step()\n",
    "    \n",
    "def validate(model, loader, epoch, nb_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_f1 = 0.0\n",
    "    running_corrects = 0\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(loader):\n",
    "            img = batch['img'].float().to(device)\n",
    "            label = batch['label'].long().to(device)\n",
    "\n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            # stats\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            correct = torch.eq(preds, label).sum()\n",
    "            running_loss += loss.item() \n",
    "            running_corrects+=correct\n",
    "    \n",
    "            for item in label.cpu().numpy():\n",
    "                y_true.append(item)\n",
    "            for item in preds.cpu().numpy():\n",
    "                y_pred.append(item)\n",
    "\n",
    "        epoch_loss = running_loss / len(loader.dataset)\n",
    "        epoch_acc = running_corrects / len(loader.dataset)\n",
    "        epoch_f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "        epoch_f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "        \n",
    "        writer.add_scalar('Loss/Valid', epoch_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Valid', epoch_acc, epoch)\n",
    "        writer.add_scalar('F1_macro/Valid', epoch_f1_macro, epoch)\n",
    "        writer.add_scalar('F1_weighted/Valid', epoch_f1_weighted, epoch)\n",
    "        \n",
    "        print(f'{running_corrects}/{len(loader.dataset)} correct' )\n",
    "        print(f'Valid loss: {epoch_loss:.6f}, Valid ACC: {epoch_acc:.6f}, F1_macro: {epoch_f1_macro:.6f}, F1_weighted: {epoch_f1_weighted:.6f}')\n",
    "        \n",
    "        val_acc_list.append(epoch_acc)\n",
    "        val_f1_macro_list.append(epoch_f1_macro)\n",
    "        val_f1_weighted_list.append(epoch_f1_weighted)\n",
    "        \n",
    "        if np.max(val_f1_macro_list) == val_f1_macro_list[-1]:  # 현재 모델이 성능 최댓값이면 저장 \n",
    "            torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='logs/' + save_name)\n",
    "\n",
    "val_acc_list = []\n",
    "val_f1_macro_list = []\n",
    "val_f1_weighted_list = []\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(model, train_loader, epoch, EPOCHS)\n",
    "    validate(model, val_loader, epoch, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
